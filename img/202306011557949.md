### xpath语法

#### 基础语法

| 表达式   | 描述                                                         |
| -------- | ------------------------------------------------------------ |
| nodename | 选中该元素。                                                 |
| /        | 从根节点选取、或者是元素和元素间的过渡。                     |
| //       | 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。跨节点获取标签 |
| .        | 选取当前节点。                                               |
| ..       | 选取当前节点的父节点。                                       |
| @        | 定位, 选取属性值                                             |
| text()   | 选取文本。                                                   |

#### 选取未知节点

| 通配符 | 描述                 |
| ------ | -------------------- |
| *      | 匹配任何元素节点。   |
| @*     | 匹配任何属性节点。   |
| node() | 匹配任何类型的节点。 |

#### 总结

1. xpath的概述XPath (XML Path Language),解析查找提取信息的语言

2. xpath的节点关系:根节点,子节点,同级节点

3. xpath的重点语法获取任意节点:`//`

4. xpath的重点语法根据属性获取节点:`标签[@属性 = '值']`

5. xpath中获取节点的文本：`text（）`

6. xpath的获取节点属性值:`@属性名`

   

#### 转义字符

在需要在字符中使用特殊字符时，python 用反斜杠转义字符。如下表：

| 转义字符 | 描述                                         |
| :------- | :------------------------------------------- |
| \        | (在行尾时)续行符                             |
| \\       | 反斜杠符号                                   |
| `\'`     | 单引号                                       |
| `\"`     | 双引号                                       |
| \a       | 响铃                                         |
| \b       | 退格(Backspace)                              |
| \e       | 转义                                         |
| \000     | 空                                           |
| \n       | 换行                                         |
| \v       | 纵向制表符                                   |
| \t       | 横向制表符                                   |
| \r       | 回车                                         |
| \f       | 换页                                         |
| \oyy     | 八进制数，yy代表的字符，例如：\o12代表换行   |
| \xyy     | 十六进制数，yy代表的字符，例如：\x0a代表换行 |
| \other   | 其它的字符以普通格式输出                     |

### 图片和音乐的爬取

http://pic.netbian.com/4kqiche/

```python
import requests
from lxml import etree

url_ = 'http://pic.netbian.com/'

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}


def page():
    url_list = []
    for i in range(25):
        url = f'http://pic.netbian.com/4kqiche/index_{i + 1}.html'
        url_list.append(url)
    return url_list


def get_url(url, headers):
    response = requests.get(url, headers=headers)
    response.encoding = response.apparent_encoding
    return response


def parse_url(text):
    info = []
    html = etree.HTML(text.text)
    name = html.xpath('//ul[@class="clearfix"]/li/a/b/text()')
    pic_url = html.xpath('//ul[@class="clearfix"]/li/a/img/@src')
    for i in range(len(name)):
        # print(name[i], url.rstrip('/').replace('4kqiche', '') + pic_url[i])
        info.append([name[i], url_ + pic_url[i]])
    return info


def save_image(list):
    for i in range(len(list)):
        pic_res = get_url(list[i][1], headers)
        with open("pic/" + list[i][0] + ".png", mode='wb') as f:
            f.write(pic_res.content)
            print(list[i][0] + ".png 保存成功")


if __name__ == '__main__':
    for p in page():
        print(p)
        info = parse_url(get_url(p, headers))
        save_image(info)
```

https://sc.chinaz.com/tupian/

```python
import re

import requests
from lxml import etree

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}


def page():
    url_list = []
    for i in range(100):
        url = f'https://sc.chinaz.com/tupian/index_{i + 1}.html'
        # https://sc.chinaz.com/tupian/index_3.html
        # print(url)
        url_list.append(url)
    return url_list


def get_url(url, headers):
    response = requests.get(url, headers=headers)
    response.encoding = response.apparent_encoding
    # print(response.url)
    return response


def parse_url(response):
    info = []
    # print(response.text)
    name = re.findall('<a class=".*" href=".*title=".*" target="_blank">(.*?)</a>', response.text, re.S)
    pic_url = re.findall('data-original="(.*?)"', response.text, re.S)
    for i in range(len(name)):
        # print(name[i], "https:" + pic_url[i])
        info.append([name[i], "https:" + pic_url[i]])
    return info


def save_image(list):
    for i in range(len(list)):
        pic_res = get_url(list[i][1], headers)
        with open("pic_2/" + list[i][0] + ".png", mode='wb') as f:
            f.write(pic_res.content)
            print(list[i][0] + ".png 保存成功")


if __name__ == '__main__':
    for p in page():
        # print(p)
        info = parse_url(get_url(p, headers))
        save_image(info)
```

